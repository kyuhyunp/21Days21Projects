{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":273490,"sourceType":"modelInstanceVersion","modelInstanceId":234165,"modelId":255866}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !git clone https://github.com/AshishJangra27/Face-Generator-with-GAN\n\nimport os\nimport numpy as np\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport imageio\nfrom tqdm import tqdm\n\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n\ngenerator = tf.keras.models.load_model('/kaggle/working/Face-Generator-with-GAN/generator_700.h5', compile=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T09:25:32.292635Z","iopub.execute_input":"2025-03-03T09:25:32.293008Z","iopub.status.idle":"2025-03-03T09:25:32.306776Z","shell.execute_reply.started":"2025-03-03T09:25:32.292974Z","shell.execute_reply":"2025-03-03T09:25:32.305706Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1. Generate Images","metadata":{}},{"cell_type":"code","source":"noise = tf.random.normal([1, 100])\n\nwith tf.device('/CPU:0'):\n    generated_images = generator(noise, training=False)\n\ngenerated_images = (generated_images + 1) / 2.0\n\nplt.imshow(generated_images[0])\nplt.axis('off')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T08:51:53.085942Z","iopub.execute_input":"2025-03-03T08:51:53.086327Z","iopub.status.idle":"2025-03-03T08:51:53.52393Z","shell.execute_reply.started":"2025-03-03T08:51:53.086294Z","shell.execute_reply":"2025-03-03T08:51:53.522725Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. Bulk Generation","metadata":{}},{"cell_type":"code","source":"def generate_multiple_images(model, noise_dim=100, num_images=10):\n    fig, axes = plt.subplots(2, 5, figsize=(15, 7))  # 10 rows, 5 columns\n\n    for i in range(num_images):\n        noise = tf.random.normal([1, noise_dim])  # Generate random noise\n\n        with tf.device('/CPU:0'):\n            generated_image = model(noise, training=False)\n\n        generated_image = (generated_image + 1) / 2.0  # Rescale for visualization\n\n        # Plot the generated image\n        ax = axes[i // 5, i % 5]  # Row-wise placement\n        ax.imshow(generated_image[0])\n        ax.axis('off')\n        ax.set_title(f\"Image {i+1}\", fontsize=12, pad=10)\n\n    plt.subplots_adjust(wspace=0.3, hspace=0.3)  # Adjust spacing between images\n    plt.show()\n\ngenerate_multiple_images(generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T08:54:24.225764Z","iopub.execute_input":"2025-03-03T08:54:24.226148Z","iopub.status.idle":"2025-03-03T08:54:25.847916Z","shell.execute_reply.started":"2025-03-03T08:54:24.2261Z","shell.execute_reply":"2025-03-03T08:54:25.846688Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3. Getting Classification on Faces","metadata":{}},{"cell_type":"code","source":"classifier = tf.keras.models.load_model('/kaggle/input/gender-classifier-mobilenet/keras/gender-classifier-mobilenet/1/gender_classifier.keras')\n\nnoise = tf.random.normal([1, 100])\n\ngenerated_image = generator(noise, training=False)\ngenerated_image = (generated_image + 1) / 2.0  # Rescale from [-1,1] to [0,1]\n\ngenerate_img = tf.image.resize(generated_image, (224, 224))\n\nprediction = classifier.predict(generate_img, verbose = 0)\nlabel = \"Male\" if prediction[0][0] > 0.5 else \"Female\" \n\nplt.title(label + str(prediction))\nplt.imshow(generated_image[0])\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T09:13:30.60054Z","iopub.execute_input":"2025-03-03T09:13:30.600871Z","iopub.status.idle":"2025-03-03T09:13:33.563176Z","shell.execute_reply.started":"2025-03-03T09:13:30.600845Z","shell.execute_reply":"2025-03-03T09:13:33.562128Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4. Checking Images and Predictions","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 10, figsize=(15, 7))  # 5 rows, 10 columns\nfig.subplots_adjust(hspace=0.5)  # Adjust spacing\n\nfor i in range(50):\n    noise = tf.random.normal([1, 100])\n    generated_image = generator(noise, training=False)\n    generated_image = (generated_image + 1) / 2.0  # Rescale to [0,1]\n\n    resized_img = tf.image.resize(generated_image, (224, 224))\n    resized_img = tf.expand_dims(resized_img[0], axis=0)  # Ensure batch dimension\n\n    prediction = classifier.predict(resized_img, verbose=0)\n    \n    prob = prediction[0][0]\n\n    # Classification with new conditions\n    if prob > 0.95:\n        label = \"Male\"\n    elif prob < 0.05:\n        label = \"Female\"\n    else:\n        label = \"IDK\"\n\n    row, col = divmod(i, 10)  # Calculate grid position\n    axes[row, col].imshow(generated_image[0])\n    axes[row, col].set_title(label, fontsize=8)\n    axes[row, col].axis('off')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T09:17:46.883521Z","iopub.execute_input":"2025-03-03T09:17:46.883917Z","iopub.status.idle":"2025-03-03T09:18:09.658777Z","shell.execute_reply.started":"2025-03-03T09:17:46.883885Z","shell.execute_reply":"2025-03-03T09:18:09.65753Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5. Checking High Quality Male Images","metadata":{}},{"cell_type":"code","source":"male_images = []\npbar = tqdm(total=10, desc=\"Generating High-Confidence Male Images\")  # Progress Bar\n\n# Generate images until we have 10 males with high confidence\nwhile len(male_images) < 10:\n    noise = tf.random.normal([1, 100])\n    generated_image = generator(noise, training=False)\n    generated_image = (generated_image + 1) / 2.0  # Rescale to [0,1]\n\n    resized_img = tf.image.resize(generated_image, (224, 224))\n    resized_img = tf.expand_dims(resized_img[0], axis=0)  # Ensure batch dimension\n\n    prediction = classifier.predict(resized_img, verbose=0)\n    prob = prediction[0][0]\n\n    # Keep only males with high confidence (>0.99)\n    if prob > 0.99:\n        male_images.append((generated_image[0], prob))  # Store image & confidence\n        pbar.update(1)  # Update progress bar\n\npbar.close()  # Close progress bar when done\n\n# Plot the 10 high-confidence male images\nfig, axes = plt.subplots(2, 5, figsize=(15, 6))  # 2 rows, 5 columns\nfig.subplots_adjust(hspace=0.5)\n\nfor i, (img, prob) in enumerate(male_images):\n    row, col = divmod(i, 5)\n    axes[row, col].imshow(img)\n    axes[row, col].set_title(f\"Male ({prob:.2f})\", fontsize=10)\n    axes[row, col].axis('off')\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T09:28:41.750215Z","iopub.execute_input":"2025-03-03T09:28:41.750607Z","iopub.status.idle":"2025-03-03T09:29:01.295585Z","shell.execute_reply.started":"2025-03-03T09:28:41.750579Z","shell.execute_reply":"2025-03-03T09:29:01.29436Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 6. Generating High Quality Male Images","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom PIL import Image\n\noutput_folder = \"generated_males\"\nos.makedirs(output_folder, exist_ok=True)\n\n# Initialize CSV data storage\ndata = []\n\n# Initialize progress bar\nnum_images = 1000\npbar = tqdm(total=num_images, desc=\"Generating High-Confidence Male Images\")\n\nmale_count = 0\n\n# Generate images until we have 1000 males with high confidence\nwhile male_count < num_images:\n    noise = tf.random.normal([1, 100])  # Generate noise vector\n    generated_image = generator(noise, training=False)\n    generated_image = (generated_image + 1) / 2.0  # Rescale to [0,1]\n\n    resized_img = tf.image.resize(generated_image, (224, 224))\n    resized_img = tf.expand_dims(resized_img[0], axis=0)  # Ensure batch dimension\n\n    prediction = classifier.predict(resized_img, verbose=0)\n    prob = prediction[0][0]\n\n    # Keep only males with high confidence (>0.99)\n    if prob > 0.99:\n        file_path = os.path.join(output_folder, f\"male_{male_count:04d}.png\")\n        \n        # Convert Tensor to Image and Save\n        img_array = (generated_image[0].numpy() * 255).astype(np.uint8)\n        img = Image.fromarray(img_array)\n        img.save(file_path)\n\n        # Store noise vector and file path in data list\n        data.append([file_path, noise.numpy().tolist()])\n\n        male_count += 1  # Increment count\n        pbar.update(1)  # Update progress bar\n\npbar.close()  # Close progress bar\n\n# Save noise vectors and image paths in a CSV file\ndf = pd.DataFrame(data, columns=[\"file_path\", \"noise_vector\"])\ncsv_path = \"male_images_data.csv\"\ndf.to_csv(csv_path, index=False)\n\nprint(f\"‚úÖ Successfully generated {num_images} male images.\")\nprint(f\"üìÅ Images saved in: {output_folder}\")\nprint(f\"üìÑ CSV file saved as: {csv_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T09:34:30.112962Z","iopub.execute_input":"2025-03-03T09:34:30.113348Z","iopub.status.idle":"2025-03-03T10:20:17.020434Z","shell.execute_reply.started":"2025-03-03T09:34:30.113317Z","shell.execute_reply":"2025-03-03T10:20:17.019177Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 7. Generating High Quality Female Images","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom PIL import Image\n\noutput_folder = \"generated_females\"\nos.makedirs(output_folder, exist_ok=True)\n\n# Initialize CSV data storage\ndata = []\n\n# Initialize progress bar\nnum_images = 1000\npbar = tqdm(total=num_images, desc=\"Generating High-Confidence Female Images\")\n\nmale_count = 0\n\n\nwhile male_count < num_images:\n    noise = tf.random.normal([1, 100])  # Generate noise vector\n    generated_image = generator(noise, training=False)\n    generated_image = (generated_image + 1) / 2.0  # Rescale to [0,1]\n\n    resized_img = tf.image.resize(generated_image, (224, 224))\n    resized_img = tf.expand_dims(resized_img[0], axis=0)  # Ensure batch dimension\n\n    prediction = classifier.predict(resized_img, verbose=0)\n    prob = prediction[0][0]\n\n    # Keep only female with high confidence (>0.01)\n    if prob < 0.01:\n        file_path = os.path.join(output_folder, f\"female_{male_count:04d}.png\")\n        \n        # Convert Tensor to Image and Save\n        img_array = (generated_image[0].numpy() * 255).astype(np.uint8)\n        img = Image.fromarray(img_array)\n        img.save(file_path)\n\n        # Store noise vector and file path in data list\n        data.append([file_path, noise.numpy().tolist()])\n\n        male_count += 1  # Increment count\n        pbar.update(1)  # Update progress bar\n\npbar.close()  # Close progress bar\n\n# Save noise vectors and image paths in a CSV file\ndf = pd.DataFrame(data, columns=[\"file_path\", \"noise_vector\"])\ncsv_path = \"female_images_data.csv\"\ndf.to_csv(csv_path, index=False)\n\nprint(f\"‚úÖ Successfully generated {num_images} female images.\")\nprint(f\"üìÅ Images saved in: {output_folder}\")\nprint(f\"üìÑ CSV file saved as: {csv_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:20:39.530095Z","iopub.execute_input":"2025-03-03T10:20:39.530501Z","iopub.status.idle":"2025-03-03T10:34:35.866599Z","shell.execute_reply.started":"2025-03-03T10:20:39.53047Z","shell.execute_reply":"2025-03-03T10:34:35.865379Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 8. Finding Gender Vector","metadata":{}},{"cell_type":"code","source":"import ast\n\nmale_vec   = pd.read_csv('/kaggle/working/male_images_data.csv')['noise_vector']\nfemale_vec = pd.read_csv('/kaggle/working/female_images_data.csv')['noise_vector']\n\nmale_vec = np.array([np.array(ast.literal_eval(vec)) for vec in male_vec])\nfemale_vec = np.array([np.array(ast.literal_eval(vec)) for vec in female_vec])\n\navg_male_vec = np.mean(male_vec, axis=0)\navg_female_vec = np.mean(female_vec, axis=0)\n\nprint(\"Average Noise Vector (Male):\", avg_male_vec)\nprint(\"Average Noise Vector (Female):\", avg_female_vec)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:43:46.671223Z","iopub.execute_input":"2025-03-03T10:43:46.671569Z","iopub.status.idle":"2025-03-03T10:43:47.461456Z","shell.execute_reply.started":"2025-03-03T10:43:46.671542Z","shell.execute_reply":"2025-03-03T10:43:47.460515Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 9. Display Vectors","metadata":{}},{"cell_type":"code","source":"def generate_and_predict(noise_vec):\n    generated_img = generator(noise_vec, training=False)\n    generated_img = (generated_img + 1) / 2.0  # Rescale from [-1,1] to [0,1]\n    resized_img = tf.image.resize(generated_img, (224, 224))\n    prediction = classifier.predict(resized_img, verbose=0)\n    label = \"Male\" if prediction[0][0] > 0.5 else \"Female\"\n    return generated_img[0], f\"{label} ({prediction[0][0]:.2f})\"\n\nmale_img, male_label = generate_and_predict(avg_male_vec)\nfemale_img, female_label = generate_and_predict(avg_female_vec)\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\naxes[0].imshow(male_img)\naxes[0].set_title(male_label)\naxes[0].axis(\"off\")\n\naxes[1].imshow(female_img)\naxes[1].set_title(female_label)\naxes[1].axis(\"off\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:44:44.765698Z","iopub.execute_input":"2025-03-03T10:44:44.766096Z","iopub.status.idle":"2025-03-03T10:44:45.911999Z","shell.execute_reply.started":"2025-03-03T10:44:44.766053Z","shell.execute_reply":"2025-03-03T10:44:45.91098Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 10. Getting Gender Vector","metadata":{}},{"cell_type":"code","source":"gender_vec = avg_male_vec - avg_female_vec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:49:28.73222Z","iopub.execute_input":"2025-03-03T10:49:28.732567Z","iopub.status.idle":"2025-03-03T10:49:28.736777Z","shell.execute_reply.started":"2025-03-03T10:49:28.732537Z","shell.execute_reply":"2025-03-03T10:49:28.735564Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 11. Testing Gender Style Transfer","metadata":{}},{"cell_type":"markdown","source":"#### 11.1) Checking different variations of same image","metadata":{}},{"cell_type":"code","source":"def generate(noise):\n    return (generator(noise, training=False) + 1) / 2.0 \n\nnoise = tf.random.normal([1, 100])\nmodifications = [2, 1.5, 1, 0.5, 0, -0.5, -1, -1.5, -2]\n\nfig, axes = plt.subplots(1, 9, figsize=(15, 3))\n\nfor i, mod in enumerate(modifications):\n    axes[i].imshow(generate(noise + mod * gender_vec)[0])\n    axes[i].axis(\"off\")\n\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T10:58:19.905406Z","iopub.execute_input":"2025-03-03T10:58:19.905797Z","iopub.status.idle":"2025-03-03T10:58:20.678243Z","shell.execute_reply.started":"2025-03-03T10:58:19.905765Z","shell.execute_reply":"2025-03-03T10:58:20.677034Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 11.2) Checking different variations on different image","metadata":{}},{"cell_type":"code","source":"def generate(noise):\n    return (generator(noise, training=False) + 1) / 2.0  # Rescale [-1,1] to [0,1]\n\n# Generate 10 different noise vectors\nnoises = tf.random.normal([10, 100])\nmodifications = [2.5,2, 1.5, 1, 0.5, 0, -0.5, -1, -1.5, -2,-2.5]\n\nfig, axes = plt.subplots(10, 11, figsize=(15, 15))  # 10 rows, 11 columns\n\nfor row, noise in enumerate(noises):\n    for col, mod in enumerate(modifications):\n        axes[row, col].imshow(generate(noise + mod * gender_vec)[0])\n        axes[row, col].axis(\"off\")\n\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T11:01:37.052961Z","iopub.execute_input":"2025-03-03T11:01:37.053346Z","iopub.status.idle":"2025-03-03T11:01:46.368646Z","shell.execute_reply.started":"2025-03-03T11:01:37.053315Z","shell.execute_reply":"2025-03-03T11:01:46.367021Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 11.3) Checking different bulk variations on bulk image","metadata":{}},{"cell_type":"code","source":"def generate(noise):\n    return (generator(noise, training=False) + 1) / 2.0  # Rescale from [-1,1] to [0,1]\n\nnoises = tf.random.normal([20, 100])\n\nmodifications = np.linspace(-3, 3, 30)  # 30 steps from -3 to 3\n\nfig, axes = plt.subplots(20, 30, figsize=(30, 20))\n\nfor row, noise in enumerate(noises):\n    for col, mod in enumerate(modifications):\n        axes[row, col].imshow(generate(noise + mod * gender_vec)[0])\n        axes[row, col].axis(\"off\")\n\nplt.subplots_adjust(wspace=0, hspace=0)  # Remove spaces\nplt.tight_layout(pad=0) \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T11:05:51.470524Z","iopub.execute_input":"2025-03-03T11:05:51.470873Z","iopub.status.idle":"2025-03-03T11:06:36.059824Z","shell.execute_reply.started":"2025-03-03T11:05:51.470848Z","shell.execute_reply":"2025-03-03T11:06:36.058188Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 11.4) Variations of an Image with GIF","metadata":{}},{"cell_type":"code","source":"def generate(noise):\n    return (generator(noise, training=False) + 1) / 2.0  # Rescale [-1,1] to [0,1]\n\n# Start with a single noise vector\nnoise = tf.random.normal([1, 100])\n\n# Generate 30 modifications smoothly transitioning\nmodifications = np.linspace(-3, 3, 60)\n\n# Create list to store frames\nframes = []\n\n# Generate each variant and store in frames\nfor mod in modifications:\n    img = generate(noise + mod * gender_vec)[0].numpy()  # Convert tensor to NumPy array\n    frames.append((img * 255).astype(np.uint8))  # Convert to uint8 for GIF\n\nimageio.mimsave(\"face_transformation.gif\", frames, duration=5/30)  # 30 FPS over 5s\n\n# Display GIF inside a Jupyter Notebook (Optional)\nfrom IPython.display import display, Image\ndisplay(Image(filename=\"face_transformation.gif\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T13:54:13.007683Z","iopub.execute_input":"2025-03-03T13:54:13.008242Z","iopub.status.idle":"2025-03-03T13:54:16.933662Z","shell.execute_reply.started":"2025-03-03T13:54:13.008198Z","shell.execute_reply":"2025-03-03T13:54:16.931905Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 11.5) Giant GIF","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport imageio\nfrom tqdm import tqdm\n\ndef generate(noise):\n    return (generator(noise, training=False) + 1) / 2.0  # Rescale [-1,1] to [0,1]\n\n# Generate 25 different noise vectors (5x5 grid)\nnoises = tf.random.normal([25, 100])\n\n# Generate 60 smooth modifications\nmodifications = np.linspace(-3, 3, 60)\n\nframes = []\n\nfor mod in tqdm(modifications, desc=\"Generating Frames\"):\n    grid_images = []  # Store rows of the 5x5 grid\n\n    for i in range(5):  # 5 rows\n        row_images = [generate(noises[i * 5 + j] + mod * gender_vec)[0].numpy() for j in range(5)]  # 5 columns\n        grid_images.append(np.hstack(row_images))  # Stack row horizontally\n\n    stacked_frame = np.vstack(grid_images)  # Stack all rows vertically\n    frames.append((stacked_frame * 255).astype(np.uint8))  # Convert to uint8 for GIF\n\n# Save final 5√ó5 animated GIF (60 frames, 5 seconds total)\nimageio.mimsave(\"small_grid_face_transformation.gif\", frames, duration=5/60)  # 60 FPS for smooth animation\n\n# Display GIF in Jupyter Notebook (Optional)\nfrom IPython.display import display, Image\ndisplay(Image(filename=\"small_grid_face_transformation.gif\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T13:49:31.16781Z","iopub.execute_input":"2025-03-03T13:49:31.168328Z","iopub.status.idle":"2025-03-03T13:50:51.707679Z","shell.execute_reply.started":"2025-03-03T13:49:31.168291Z","shell.execute_reply":"2025-03-03T13:50:51.706305Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 12. Saving Images","metadata":{}},{"cell_type":"code","source":"import shutil\n\n# Define folder paths\nmale_folder = \"/kaggle/working/generated_males\"\nfemale_folder = \"/kaggle/working/generated_females\"\n\n# Define output zip filenames\nmale_zip = \"/kaggle/working/male_images\"\nfemale_zip = \"/kaggle/working/female_images\"\n\n# Zip the Male folder\nshutil.make_archive(male_zip, 'zip', male_folder)\n\n# Zip the Female folder\nshutil.make_archive(female_zip, 'zip', female_folder)\n\nprint(\"Zipping complete! Files saved as male_images.zip and female_images.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T13:22:51.373674Z","iopub.execute_input":"2025-03-03T13:22:51.374003Z","iopub.status.idle":"2025-03-03T13:22:53.479069Z","shell.execute_reply.started":"2025-03-03T13:22:51.373974Z","shell.execute_reply":"2025-03-03T13:22:53.478159Z"}},"outputs":[],"execution_count":null}]}