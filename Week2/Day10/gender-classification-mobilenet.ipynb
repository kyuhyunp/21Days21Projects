{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1178231,"sourceType":"datasetVersion","datasetId":669126}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nimport tensorflow as tf\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.preprocessing import image\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom keras.applications.mobilenet import MobileNet ,preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\nstrategy = tf.distribute.MirroredStrategy()\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T06:11:05.473628Z","iopub.execute_input":"2025-03-03T06:11:05.473943Z","iopub.status.idle":"2025-03-03T06:11:05.478871Z","shell.execute_reply.started":"2025-03-03T06:11:05.47392Z","shell.execute_reply":"2025-03-03T06:11:05.477913Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1. Training with Categorical Classification","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(  preprocessing_function = preprocess_input).flow_from_directory(\n                                        '/kaggle/input/gender-recognition-200k-images-celeba/Dataset/Train', \n                                        target_size = (224, 224), batch_size = 256)\n\nvalid_datagen = ImageDataGenerator( preprocessing_function = preprocess_input).flow_from_directory(\n                                    '/kaggle/input/gender-recognition-200k-images-celeba/Dataset/Test', \n                                    target_size = (224, 224), batch_size = 256)\n\ntest_datagen = ImageDataGenerator( preprocessing_function = preprocess_input).flow_from_directory(\n                                    '/kaggle/input/gender-recognition-200k-images-celeba/Dataset/Validation',\n                                    target_size = (224, 224), batch_size = 256)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T06:12:30.583876Z","iopub.execute_input":"2025-03-03T06:12:30.58418Z","iopub.status.idle":"2025-03-03T06:13:39.918408Z","shell.execute_reply.started":"2025-03-03T06:12:30.584157Z","shell.execute_reply":"2025-03-03T06:13:39.917737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mobilenet = MobileNet(include_top = False)\nx = mobilenet.output\n\nx = GlobalAveragePooling2D()(x) \nx = Dense(1024,activation='relu')(x)\nx = Dropout(0.2)(x)\nx = Dense(512,activation='relu')(x)\n\npreds = Dense(2,activation='softmax')(x)\n\nmodel = Model(inputs = mobilenet.input, outputs = preds)\n\nfor layer in model.layers[:-9]:\n    layer.trainable = False\n\nmodel.compile( optimizer = 'adam',  loss = 'categorical_crossentropy', metrics = ['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T06:13:39.919689Z","iopub.execute_input":"2025-03-03T06:13:39.919909Z","iopub.status.idle":"2025-03-03T06:13:40.380092Z","shell.execute_reply.started":"2025-03-03T06:13:39.91989Z","shell.execute_reply":"2025-03-03T06:13:40.379435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filepath = \"saved-model-{epoch:02d}.keras\"\ncheckpoint = ModelCheckpoint(filepath, verbose=1, save_best_only=False, mode='max')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T06:13:40.381766Z","iopub.execute_input":"2025-03-03T06:13:40.382121Z","iopub.status.idle":"2025-03-03T06:13:40.385903Z","shell.execute_reply.started":"2025-03-03T06:13:40.382086Z","shell.execute_reply":"2025-03-03T06:13:40.385229Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_datagen,\n    steps_per_epoch=train_datagen.samples // train_datagen.batch_size,\n    validation_data=valid_datagen,\n    validation_steps=valid_datagen.samples // valid_datagen.batch_size,\n    callbacks=[checkpoint],\n    epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T06:13:40.386635Z","iopub.execute_input":"2025-03-03T06:13:40.386841Z","iopub.status.idle":"2025-03-03T07:02:00.393144Z","shell.execute_reply.started":"2025-03-03T06:13:40.386824Z","shell.execute_reply":"2025-03-03T07:02:00.392441Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. Training with Binary Classification","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(  preprocessing_function = preprocess_input).flow_from_directory(\n                                        '/kaggle/input/gender-recognition-200k-images-celeba/Dataset/Train', \n                                        target_size = (224, 224), batch_size = 256, class_mode = 'binary')\n\nvalid_datagen = ImageDataGenerator( preprocessing_function = preprocess_input).flow_from_directory(\n                                    '/kaggle/input/gender-recognition-200k-images-celeba/Dataset/Test', \n                                    target_size = (224, 224), batch_size = 256, class_mode = 'binary')\n\ntest_datagen = ImageDataGenerator( preprocessing_function = preprocess_input).flow_from_directory(\n                                    '/kaggle/input/gender-recognition-200k-images-celeba/Dataset/Validation',\n                                    target_size = (224, 224), batch_size = 256, class_mode = 'binary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T07:05:12.062476Z","iopub.execute_input":"2025-03-03T07:05:12.062777Z","iopub.status.idle":"2025-03-03T07:06:41.208867Z","shell.execute_reply.started":"2025-03-03T07:05:12.062755Z","shell.execute_reply":"2025-03-03T07:06:41.208099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mobilenet = MobileNet(include_top = False)\nx = mobilenet.output\n\nx = GlobalAveragePooling2D()(x) \nx = Dense(1024,activation='relu')(x)\nx = Dropout(0.2)(x)\nx = Dense(512,activation='relu')(x)\n\npreds = Dense(1,activation='sigmoid')(x)\n\nmodel_2 = Model(inputs = mobilenet.input, outputs = preds)\n\nfor layer in model.layers[:-9]:\n    layer.trainable = False\n\nmodel_2.compile( optimizer = 'adam',  loss = 'binary_crossentropy', metrics = ['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T07:07:28.029924Z","iopub.execute_input":"2025-03-03T07:07:28.030234Z","iopub.status.idle":"2025-03-03T07:07:28.468002Z","shell.execute_reply.started":"2025-03-03T07:07:28.030213Z","shell.execute_reply":"2025-03-03T07:07:28.467227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filepath = \"saved{epoch:02d}.keras\"\ncheckpoint = ModelCheckpoint(filepath, verbose=1, save_best_only=False, mode='max')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T07:07:30.421403Z","iopub.execute_input":"2025-03-03T07:07:30.421718Z","iopub.status.idle":"2025-03-03T07:07:30.42593Z","shell.execute_reply.started":"2025-03-03T07:07:30.421694Z","shell.execute_reply":"2025-03-03T07:07:30.425104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model_2.fit(\n    train_datagen,\n    steps_per_epoch=train_datagen.samples // train_datagen.batch_size,\n    validation_data=valid_datagen,\n    validation_steps=valid_datagen.samples // valid_datagen.batch_size,\n    callbacks=[checkpoint],\n    epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T07:07:34.182047Z","iopub.execute_input":"2025-03-03T07:07:34.182396Z","iopub.status.idle":"2025-03-03T08:02:39.50772Z","shell.execute_reply.started":"2025-03-03T07:07:34.182369Z","shell.execute_reply":"2025-03-03T08:02:39.506975Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3. Finding best Model","metadata":{}},{"cell_type":"code","source":"model_2.evaluate(test_datagen)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T08:02:51.070399Z","iopub.execute_input":"2025-03-03T08:02:51.070759Z","iopub.status.idle":"2025-03-03T08:05:59.070707Z","shell.execute_reply.started":"2025-03-03T08:02:51.070731Z","shell.execute_reply":"2025-03-03T08:05:59.069909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_2.evaluate(valid_datagen)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T08:06:29.050076Z","iopub.execute_input":"2025-03-03T08:06:29.050395Z","iopub.status.idle":"2025-03-03T08:07:27.937908Z","shell.execute_reply.started":"2025-03-03T08:06:29.050352Z","shell.execute_reply":"2025-03-03T08:07:27.937133Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4. Getting Inference","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.load_model(\"/kaggle/working/saved10.keras\")\n\ndef predict_image(img_path):\n    img = image.load_img(img_path, target_size=(224, 224))  # Resize to match model input\n    img_array = image.img_to_array(img)  # Convert to NumPy array\n    img_array = np.expand_dims(img_array, axis=0)  # Expand dims for batch processing\n    img_array = preprocess_input(img_array)  # Apply MobileNet preprocessing\n\n    # Get prediction\n    prediction = model.predict(img_array)[0][0]  # Since it's binary classification\n    \n    # Convert prediction to class label\n    class_label = \"Male\" if prediction > 0.5 else \"Female\"\n\n    # Show image with prediction\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.title(f\"Predicted: {class_label} ({prediction:.2f})\")\n    plt.show()\n\n    return class_label\n\npath = '/kaggle/input/gender-recognition-200k-images-celeba/Dataset/Train/Male/'\nimage_path = path + os.listdir('/kaggle/input/gender-recognition-200k-images-celeba/Dataset/Train/Male')[0]\n\npredicted_label = predict_image(image_path)\nprint(f\"Predicted Class: {predicted_label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T08:10:13.748914Z","iopub.execute_input":"2025-03-03T08:10:13.749213Z","iopub.status.idle":"2025-03-03T08:10:17.15952Z","shell.execute_reply.started":"2025-03-03T08:10:13.749191Z","shell.execute_reply":"2025-03-03T08:10:17.158651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = tf.keras.models.load_model(\"/kaggle/working/saved10.keras\")\n\nmale_path = \"/kaggle/input/gender-recognition-200k-images-celeba/Dataset/Train/Male/\"\nfemale_path = \"/kaggle/input/gender-recognition-200k-images-celeba/Dataset/Train/Female/\"\n\nmale_images = random.sample(os.listdir(male_path), 25)\nfemale_images = random.sample(os.listdir(female_path), 25)\n\nall_images = [(male_path + img, \"Male\") for img in male_images] + [(female_path + img, \"Female\") for img in female_images]\nrandom.shuffle(all_images)\n\ndef predict_image(img_path):\n\n    img = image.load_img(img_path, target_size=(224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n\n    prediction = model.predict(img_array, verbose = 0)[0][0]  # Since it's binary classification\n    class_label = \"Male\" if prediction > 0.5 else \"Female\"\n    \n    return img, class_label, prediction  # Return image object, label, and confidence score\n\n# Create 10x5 subplot\nfig, axes = plt.subplots(10, 5, figsize=(15, 30))\n\nfor i, (img_path, true_label) in enumerate(all_images):\n    img, predicted_label, confidence = predict_image(img_path)\n    ax = axes[i // 5, i % 5]  # Calculate subplot position\n    ax.imshow(img)\n    ax.axis(\"off\")\n    ax.set_title(f\"P: {predicted_label} ({confidence:.2f})\\nT: {true_label}\", fontsize=10)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T08:16:45.523035Z","iopub.execute_input":"2025-03-03T08:16:45.523333Z","iopub.status.idle":"2025-03-03T08:16:56.798964Z","shell.execute_reply.started":"2025-03-03T08:16:45.523312Z","shell.execute_reply":"2025-03-03T08:16:56.797502Z"}},"outputs":[],"execution_count":null}]}